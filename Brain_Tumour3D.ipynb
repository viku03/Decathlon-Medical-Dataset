{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from scipy.ndimage import rotate\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumor3DDataset:\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = base_path\n",
    "        self.dataset_json = self._load_dataset_json()\n",
    "        self.train_files = self._get_training_files()\n",
    "        \n",
    "    def _load_dataset_json(self):\n",
    "        json_path = os.path.join(self.base_path, 'ML_Decathlon_Dataset/Task01_BrainTumour/dataset.json')\n",
    "        with open(json_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def _get_training_files(self):\n",
    "        return self.dataset_json['training']\n",
    "    \n",
    "    def validate_data_integrity(self, images, labels):\n",
    "        \"\"\"Validate data integrity and check for potential issues.\"\"\"\n",
    "        print(\"\\nData Validation Report:\")\n",
    "        print(\"-----------------------\")\n",
    "        \n",
    "        # Check shapes\n",
    "        print(f\"Number of samples: {len(images)}\")\n",
    "        print(f\"Image shape: {images[0].shape}\")\n",
    "        print(f\"Label shape: {labels[0].shape}\")\n",
    "        \n",
    "        # Check value ranges\n",
    "        for i, (img, lbl) in enumerate(zip(images, labels)):\n",
    "            print(f\"\\nSample {i}:\")\n",
    "            print(f\"Image value range: [{np.min(img):.3f}, {np.max(img):.3f}]\")\n",
    "            print(f\"Unique labels: {np.unique(lbl)}\")\n",
    "            \n",
    "            # Check for NaN/Inf\n",
    "            if np.any(np.isnan(img)) or np.any(np.isinf(img)):\n",
    "                print(\"WARNING: Found NaN or Inf values in image!\")\n",
    "            \n",
    "            # Check label validity\n",
    "            if not np.array_equal(np.unique(lbl), np.arange(len(np.unique(lbl)))):\n",
    "                print(\"WARNING: Labels might not be consecutive integers!\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def load_volume(self, file_path):\n",
    "        full_path = os.path.join(self.base_path, 'ML_Decathlon_Dataset/Task01_BrainTumour', \n",
    "                                file_path.replace('./', ''))\n",
    "        return nib.load(full_path).get_fdata()\n",
    "\n",
    "    def analyze_class_distribution(self, labels):\n",
    "        \"\"\"Analyze class distribution in the dataset\"\"\"\n",
    "        class_counts = {}\n",
    "        total_voxels = 0\n",
    "        \n",
    "        for label_volume in labels:\n",
    "            unique, counts = np.unique(label_volume, return_counts=True)\n",
    "            total_voxels += label_volume.size\n",
    "            \n",
    "            for class_idx, count in zip(unique, counts):\n",
    "                if class_idx not in class_counts:\n",
    "                    class_counts[class_idx] = 0\n",
    "                class_counts[class_idx] += count\n",
    "        \n",
    "        # Convert to percentages\n",
    "        class_percentages = {k: (v/total_voxels)*100 for k, v in class_counts.items()}\n",
    "        \n",
    "        return class_counts, class_percentages\n",
    "\n",
    "    def preprocess_volume(self, volume):\n",
    "        \"\"\"Optimized preprocessing using vectorized operations\"\"\"\n",
    "        preprocessed = np.zeros_like(volume, dtype=np.float32)\n",
    "        for i in range(volume.shape[-1]):\n",
    "            modality = volume[..., i]\n",
    "            nonzero_mask = modality != 0\n",
    "            if np.any(nonzero_mask):\n",
    "                mean = np.mean(modality[nonzero_mask])\n",
    "                std = np.std(modality[nonzero_mask])\n",
    "                if std != 0:\n",
    "                    preprocessed[..., i] = (modality - mean) / std\n",
    "        return preprocessed\n",
    "\n",
    "    def prepare_data(self, num_samples=None):\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        train_files = self.train_files[:num_samples] if num_samples else self.train_files\n",
    "        \n",
    "        for idx, file_info in tqdm(enumerate(train_files), desc=\"Loading data\", total=len(train_files)):\n",
    "            try:\n",
    "                image = self.load_volume(file_info['image'])\n",
    "                label = self.load_volume(file_info['label'])\n",
    "                \n",
    "                # Check for potential data issues\n",
    "                if np.any(np.isnan(image)) or np.any(np.isinf(image)):\n",
    "                    print(f\"Warning: Found NaN or Inf values in image {idx}\")\n",
    "                    continue\n",
    "                \n",
    "                image = self.preprocess_volume(image)\n",
    "                \n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "                gc.collect()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {idx}: {e}\")\n",
    "                continue\n",
    "            \n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator3D(Sequence):\n",
    "    def __init__(self, image_list, label_list, batch_size=1, patch_size=(64, 64, 64),\n",
    "                 n_channels=4, n_classes=4, shuffle=True, augment=False):\n",
    "        self.image_list = image_list\n",
    "        self.label_list = label_list\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        \n",
    "        self.valid_patches = []\n",
    "        self._calculate_valid_patches()\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def _calculate_valid_patches(self):\n",
    "        valid_patches = []\n",
    "        stride = [p // 2 for p in self.patch_size]\n",
    "        \n",
    "        for idx, image in enumerate(self.image_list):\n",
    "            x_coords = range(0, image.shape[0] - self.patch_size[0], stride[0])\n",
    "            y_coords = range(0, image.shape[1] - self.patch_size[1], stride[1])\n",
    "            z_coords = range(0, image.shape[2] - self.patch_size[2], stride[2])\n",
    "            \n",
    "            for x in x_coords:\n",
    "                for y in y_coords:\n",
    "                    for z in z_coords:\n",
    "                        label_patch = self.label_list[idx][\n",
    "                            x:x + self.patch_size[0],\n",
    "                            y:y + self.patch_size[1],\n",
    "                            z:z + self.patch_size[2]\n",
    "                        ]\n",
    "                        if np.any(label_patch):  # Only include patches with labels\n",
    "                            valid_patches.append((idx, x, y, z))\n",
    "        \n",
    "        self.valid_patches = valid_patches\n",
    "        print(f\"Total valid patches: {len(self.valid_patches)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.valid_patches) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = min((index + 1) * self.batch_size, len(self.valid_patches))\n",
    "        batch_patches = self.valid_patches[start_idx:end_idx]\n",
    "        \n",
    "        batch_size = len(batch_patches)\n",
    "        X = np.zeros((batch_size, *self.patch_size, self.n_channels), dtype=np.float32)\n",
    "        y = np.zeros((batch_size, *self.patch_size, self.n_classes), dtype=np.float32)\n",
    "\n",
    "        for i, (img_idx, x, y_coord, z) in enumerate(batch_patches):\n",
    "            X[i], y[i] = self._extract_patch(img_idx, x, y_coord, z)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def _extract_patch(self, img_idx, x, y, z):\n",
    "        image = self.image_list[img_idx]\n",
    "        label = self.label_list[img_idx]\n",
    "\n",
    "        patch_x = image[x:x + self.patch_size[0],\n",
    "                       y:y + self.patch_size[1],\n",
    "                       z:z + self.patch_size[2]].astype(np.float32)\n",
    "\n",
    "        patch_y = np.zeros((*self.patch_size, self.n_classes), dtype=np.float32)\n",
    "        for c in range(self.n_classes):\n",
    "            patch_y[..., c] = (label[x:x + self.patch_size[0],\n",
    "                                    y:y + self.patch_size[1],\n",
    "                                    z:z + self.patch_size[2]] == c)\n",
    "\n",
    "        if self.augment:\n",
    "            patch_x, patch_y = self._augment_data(patch_x, patch_y)\n",
    "\n",
    "        return patch_x, patch_y\n",
    "\n",
    "    @staticmethod\n",
    "    def _augment_data(image, label):\n",
    "        if np.random.random() > 0.5:\n",
    "            angle = np.random.uniform(-20, 20)\n",
    "            image = np.stack([rotate(image[..., c], angle, axes=(0, 1), reshape=False)\n",
    "                            for c in range(image.shape[-1])], axis=-1)\n",
    "            label = np.stack([rotate(label[..., c], angle, axes=(0, 1), reshape=False)\n",
    "                            for c in range(label.shape[-1])], axis=-1)\n",
    "        return image, label\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.valid_patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3d_unet(input_shape, n_classes=4, n_filters=16):\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = conv_block_3d(inputs, n_filters)\n",
    "    pool1 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "    \n",
    "    conv2 = conv_block_3d(pool1, n_filters*2)\n",
    "    pool2 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "    \n",
    "    conv3 = conv_block_3d(pool2, n_filters*4)\n",
    "    pool3 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "    \n",
    "    # Bridge\n",
    "    conv4 = conv_block_3d(pool3, n_filters*8)\n",
    "    \n",
    "    # Decoder\n",
    "    up5 = tf.keras.layers.Conv3DTranspose(n_filters*4, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv4)\n",
    "    concat5 = tf.keras.layers.concatenate([up5, conv3])\n",
    "    conv5 = conv_block_3d(concat5, n_filters*4)\n",
    "    \n",
    "    up6 = tf.keras.layers.Conv3DTranspose(n_filters*2, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv5)\n",
    "    concat6 = tf.keras.layers.concatenate([up6, conv2])\n",
    "    conv6 = conv_block_3d(concat6, n_filters*2)\n",
    "    \n",
    "    up7 = tf.keras.layers.Conv3DTranspose(n_filters, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv6)\n",
    "    concat7 = tf.keras.layers.concatenate([up7, conv1])\n",
    "    conv7 = conv_block_3d(concat7, n_filters)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv3D(n_classes, (1, 1, 1), activation='softmax')(conv7)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_3d(inputs, n_filters, kernel_size=(3, 3, 3)):\n",
    "    x = tf.keras.layers.Conv3D(n_filters, kernel_size, padding='same')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv3D(n_filters, kernel_size, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-5\n",
    "    \n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred) + smooth\n",
    "    denominator = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth\n",
    "    \n",
    "    return 1 - numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingController:\n",
    "    def __init__(self):\n",
    "        self.stop_training = False\n",
    "        # Create button widget\n",
    "        self.button = widgets.Button(\n",
    "            description='Stop Training',\n",
    "            button_style='danger',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltip='Click to stop training after current batch',\n",
    "            icon='stop'  # (optional) icon name from Font Awesome\n",
    "        )\n",
    "        self.button.on_click(self.on_button_clicked)\n",
    "        self.status_label = widgets.Label(value='Training in progress...')\n",
    "        self.container = widgets.VBox([self.button, self.status_label])\n",
    "        display(self.container)\n",
    "    \n",
    "    def on_button_clicked(self, b):\n",
    "        self.stop_training = True\n",
    "        self.status_label.value = \"Stopping... Please wait for current batch to complete.\"\n",
    "        print(\"\\nStop signal received. Training will stop after current batch...\")\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, controller):\n",
    "        super().__init__()\n",
    "        self.controller = controller\n",
    "        self.batch_count = 0\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(\"Training started. Press the Stop button or Ctrl+C to stop training safely.\")\n",
    "    \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.batch_count += 1\n",
    "        # Check stop condition every batch\n",
    "        if self.controller.stop_training:\n",
    "            self.model.stop_training = True\n",
    "            print(f\"\\nTraining stopped at batch {self.batch_count}\")\n",
    "            # Save model immediately\n",
    "            self.model.save(f'model_stopped_batch_{self.batch_count}.keras')\n",
    "            print(f\"Model saved as model_stopped_batch_{self.batch_count}.keras\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Save model at the end of each epoch\n",
    "        self.model.save(f'model_epoch_{epoch}.keras')\n",
    "        if self.controller.stop_training:\n",
    "            print(f\"\\nTraining stopped at epoch {epoch}\")\n",
    "            self.controller.status_label.value = f\"Training stopped at epoch {epoch}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3d_unet_weighted(input_shape, n_classes=4, n_filters=16):\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = conv_block_3d(inputs, n_filters)\n",
    "    pool1 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "    \n",
    "    conv2 = conv_block_3d(pool1, n_filters*2)\n",
    "    pool2 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "    \n",
    "    conv3 = conv_block_3d(pool2, n_filters*4)\n",
    "    pool3 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "    \n",
    "    # Bridge\n",
    "    conv4 = conv_block_3d(pool3, n_filters*8)\n",
    "    \n",
    "    # Decoder\n",
    "    up5 = tf.keras.layers.Conv3DTranspose(n_filters*4, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv4)\n",
    "    concat5 = tf.keras.layers.concatenate([up5, conv3])\n",
    "    conv5 = conv_block_3d(concat5, n_filters*4)\n",
    "    \n",
    "    up6 = tf.keras.layers.Conv3DTranspose(n_filters*2, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv5)\n",
    "    concat6 = tf.keras.layers.concatenate([up6, conv2])\n",
    "    conv6 = conv_block_3d(concat6, n_filters*2)\n",
    "    \n",
    "    up7 = tf.keras.layers.Conv3DTranspose(n_filters, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv6)\n",
    "    concat7 = tf.keras.layers.concatenate([up7, conv1])\n",
    "    conv7 = conv_block_3d(concat7, n_filters)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv3D(n_classes, (1, 1, 1), activation='softmax')(conv7)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-5\n",
    "    \n",
    "    # Convert to float32\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    # Calculate class weights based on inverse frequency\n",
    "    weights = tf.reduce_sum(y_true, axis=[0,1,2,3])\n",
    "    weights = 1.0 / (weights + smooth)\n",
    "    weights = weights / tf.reduce_sum(weights)  # Normalize weights\n",
    "    \n",
    "    # Calculate weighted Dice loss for each class\n",
    "    numerator = 2.0 * tf.reduce_sum(y_true * y_pred * weights, axis=[0,1,2,3])\n",
    "    denominator = tf.reduce_sum((y_true + y_pred) * weights, axis=[0,1,2,3])\n",
    "    \n",
    "    dice_scores = (numerator + smooth) / (denominator + smooth)\n",
    "    return 1.0 - tf.reduce_mean(dice_scores)\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-5\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1,2,3]) + tf.reduce_sum(y_pred, axis=[1,2,3])\n",
    "    \n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "def train_weighted_model(validation_split=0.2, max_epochs=5, num_samples=10):\n",
    "    try:\n",
    "        # Initialize controller\n",
    "        controller = TrainingController()\n",
    "        \n",
    "        # Setup keyboard interrupt handler\n",
    "        original_sigint = signal.getsignal(signal.SIGINT)\n",
    "        def keyboard_interrupt_handler(sig, frame):\n",
    "            print(\"\\nKeyboard interrupt (Ctrl+C) detected. Stopping training safely...\")\n",
    "            controller.stop_training = True\n",
    "            # Restore original SIGINT handler\n",
    "            signal.signal(signal.SIGINT, original_sigint)\n",
    "        \n",
    "        # Set up the keyboard interrupt handler\n",
    "        signal.signal(signal.SIGINT, keyboard_interrupt_handler)\n",
    "              \n",
    "        # Load and prepare data\n",
    "        dataset = BrainTumor3DDataset(base_path='.')\n",
    "        print(\"Starting data preparation...\")\n",
    "        images, labels = dataset.prepare_data(num_samples=num_samples)\n",
    "        \n",
    "        # Validate data\n",
    "        dataset.validate_data_integrity(images, labels)\n",
    "        \n",
    "        # Analyze class distribution\n",
    "        class_counts, class_percentages = dataset.analyze_class_distribution(labels)\n",
    "        print(\"\\nClass distribution:\")\n",
    "        for class_idx, count in class_counts.items():\n",
    "            print(f\"Class {class_idx}: {count} voxels ({class_percentages[class_idx]:.2f}%)\")\n",
    "        \n",
    "        # Split data\n",
    "        print(\"\\nCreating train/val split...\")\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            images, labels, test_size=validation_split, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Clear memory\n",
    "        del images, labels\n",
    "        gc.collect()\n",
    "        \n",
    "        # Create data generators\n",
    "        patch_size = (64, 64, 64)\n",
    "        train_generator = DataGenerator3D(\n",
    "            X_train, y_train, batch_size=1, patch_size=patch_size, augment=True\n",
    "        )\n",
    "        val_generator = DataGenerator3D(\n",
    "            X_val, y_val, batch_size=1, patch_size=patch_size, augment=False\n",
    "        )\n",
    "        \n",
    "        # Create and compile model with weighted loss\n",
    "        input_shape = (*patch_size, 4)\n",
    "        model = create_3d_unet_weighted(input_shape, n_classes=4)\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "        \n",
    "        # Compile model with weighted loss and additional metrics\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=weighted_dice_loss,\n",
    "            metrics=[\n",
    "                dice_coefficient,\n",
    "                tf.keras.metrics.MeanIoU(num_classes=4),\n",
    "                tf.keras.metrics.Precision(),\n",
    "                tf.keras.metrics.Recall()\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            CustomCallback(controller),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_dice_coefficient',\n",
    "                mode='max',\n",
    "                patience=5,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                'best_3d_model_weighted.keras',\n",
    "                save_best_only=True,\n",
    "                monitor='val_dice_coefficient',\n",
    "                mode='max',\n",
    "                verbose=1\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_dice_coefficient',\n",
    "                mode='max',\n",
    "                factor=0.5,\n",
    "                patience=3,\n",
    "                min_lr=1e-6,\n",
    "                verbose=1\n",
    "            ),\n",
    "            tf.keras.callbacks.CSVLogger('training_log_weighted.csv'),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                'checkpoint_epoch_{epoch:02d}.keras',\n",
    "                save_freq='epoch',\n",
    "                verbose=1\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "        # Train model\n",
    "        try:\n",
    "            history = model.fit(\n",
    "                train_generator,\n",
    "                validation_data=val_generator,\n",
    "                epochs=max_epochs,\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTraining interrupted by user. Saving model...\")\n",
    "            model.save('interrupted_model.keras')\n",
    "            print(\"Model saved as interrupted_model.keras\")\n",
    "            return model, history\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn error occurred during training: {str(e)}\")\n",
    "            model.save('error_model.keras')\n",
    "            print(\"Model saved as error_model.keras\")\n",
    "            raise e\n",
    "        finally:\n",
    "            # Restore original SIGINT handler\n",
    "            signal.signal(signal.SIGINT, original_sigint)\n",
    "            controller.status_label.value = \"Training completed or stopped.\"\n",
    "        \n",
    "        return model, history\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'\\nAn error occurred during setup: {str(e)}')\n",
    "        raise e\n",
    "\n",
    "# Modified evaluation function to include Dice scores\n",
    "def evaluate_weighted_model(model, val_generator):\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(\"----------------\")\n",
    "    \n",
    "    val_predictions = []\n",
    "    val_true = []\n",
    "    dice_scores = []\n",
    "    \n",
    "    for i in tqdm(range(len(val_generator)), desc=\"Evaluating\"):\n",
    "        x, y = val_generator[i]\n",
    "        pred = model.predict(x, verbose=0)\n",
    "        val_predictions.append(pred)\n",
    "        val_true.append(y)\n",
    "        \n",
    "        # Calculate Dice score for this batch\n",
    "        dice = dice_coefficient(y, pred).numpy()\n",
    "        dice_scores.append(dice)\n",
    "    \n",
    "    val_pred = np.concatenate(val_predictions)\n",
    "    val_true = np.concatenate(val_true)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mean_dice = np.mean(dice_scores)\n",
    "    accuracy = np.mean(np.argmax(val_pred, axis=-1) == np.argmax(val_true, axis=-1))\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(\n",
    "        np.argmax(val_true.reshape(-1, val_true.shape[-1]), axis=-1),\n",
    "        np.argmax(val_pred.reshape(-1, val_pred.shape[-1]), axis=-1)\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Mean Dice Score: {mean_dice:.4f}\")\n",
    "    \n",
    "    # Per-class metrics\n",
    "    for i in range(val_true.shape[-1]):\n",
    "        class_acc = np.mean(\n",
    "            np.argmax(val_pred, axis=-1)[np.argmax(val_true, axis=-1) == i] == i\n",
    "        )\n",
    "        print(f\"Class {i} Accuracy: {class_acc:.4f}\")\n",
    "    \n",
    "    return accuracy, mean_dice, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(validation_split=0.2, max_epochs=5, num_samples=10):\n",
    "    try:\n",
    "        # Initialize controller\n",
    "        controller = TrainingController()\n",
    "        \n",
    "        # Load and prepare data\n",
    "        dataset = BrainTumor3DDataset(base_path='.')\n",
    "        print(\"Starting data preparation...\")\n",
    "        images, labels = dataset.prepare_data(num_samples=num_samples)\n",
    "        \n",
    "        # Validate data\n",
    "        dataset.validate_data_integrity(images, labels)\n",
    "        \n",
    "        # Split data\n",
    "        print(\"\\nCreating train/val split...\")\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            images, labels, test_size=validation_split, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Clear memory\n",
    "        del images, labels\n",
    "        gc.collect()\n",
    "        \n",
    "        # Create data generators\n",
    "        patch_size = (64, 64, 64)\n",
    "        train_generator = DataGenerator3D(\n",
    "            X_train, y_train, batch_size=1, patch_size=patch_size, augment=True\n",
    "        )\n",
    "        val_generator = DataGenerator3D(\n",
    "            X_val, y_val, batch_size=1, patch_size=patch_size, augment=False\n",
    "        )\n",
    "        \n",
    "        # Create and compile model\n",
    "        input_shape = (*patch_size, 4)\n",
    "        model = create_3d_unet(input_shape, n_classes=4)\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=dice_loss,\n",
    "            metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=4)]\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            CustomCallback(controller),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=5,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                'best_3d_model.keras',\n",
    "                save_best_only=True,\n",
    "                monitor='val_loss',\n",
    "                verbose=1\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=3,\n",
    "                min_lr=1e-6,\n",
    "                verbose=1\n",
    "            ),\n",
    "            tf.keras.callbacks.CSVLogger('training_log.csv')\n",
    "        ]\n",
    "        \n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data=val_generator,\n",
    "            epochs=max_epochs,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        return model, history\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'\\nAn error occurred during training: {str(e)}')\n",
    "        if 'model' in locals():\n",
    "            model.save('error_model.keras')\n",
    "            print('Model saved as error_model.keras')\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_generator):\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(\"----------------\")\n",
    "    \n",
    "    val_predictions = []\n",
    "    val_true = []\n",
    "    \n",
    "    for i in tqdm(range(len(val_generator)), desc=\"Evaluating\"):\n",
    "        x, y = val_generator[i]\n",
    "        pred = model.predict(x, verbose=0)\n",
    "        val_predictions.append(pred)\n",
    "        val_true.append(y)\n",
    "    \n",
    "    val_pred = np.concatenate(val_predictions)\n",
    "    val_true = np.concatenate(val_true)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = np.mean(np.argmax(val_pred, axis=-1) == np.argmax(val_true, axis=-1))\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(\n",
    "        np.argmax(val_true.reshape(-1, val_true.shape[-1]), axis=-1),\n",
    "        np.argmax(val_pred.reshape(-1, val_pred.shape[-1]), axis=-1)\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Per-class metrics\n",
    "    for i in range(val_true.shape[-1]):\n",
    "        class_acc = np.mean(\n",
    "            np.argmax(val_pred, axis=-1)[np.argmax(val_true, axis=-1) == i] == i\n",
    "        )\n",
    "        print(f\"Class {i} Accuracy: {class_acc:.4f}\")\n",
    "    \n",
    "    return accuracy, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU devices found. Running on CPU.\n",
      "\n",
      "Initializing dataset...\n",
      "\n",
      "Loading 10 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 10/10 [00:04<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution before training:\n",
      "Class 0.0: 88,051,681 voxels (98.62%)\n",
      "Class 1.0: 786,221 voxels (0.88%)\n",
      "Class 2.0: 197,447 voxels (0.22%)\n",
      "Class 3.0: 244,651 voxels (0.27%)\n",
      "\n",
      "Splitting data with 20% validation split...\n",
      "\n",
      "Initializing data generators...\n",
      "Total valid patches: 388\n",
      "Total valid patches: 86\n",
      "Training samples: 388\n",
      "Validation samples: 86\n",
      "\n",
      "Starting model training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326f91920dbb4894bc6a924b563128b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='danger', description='Stop Training', icon='stop', style=ButtonStyle(), to…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preparation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 10/10 [00:04<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Validation Report:\n",
      "-----------------------\n",
      "Number of samples: 10\n",
      "Image shape: (240, 240, 155, 4)\n",
      "Label shape: (240, 240, 155)\n",
      "\n",
      "Sample 0:\n",
      "Image value range: [-5.103, 10.282]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 1:\n",
      "Image value range: [-3.452, 12.930]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 2:\n",
      "Image value range: [-4.458, 11.208]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 3:\n",
      "Image value range: [-4.506, 12.677]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 4:\n",
      "Image value range: [-3.708, 12.848]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 5:\n",
      "Image value range: [-5.864, 10.379]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 6:\n",
      "Image value range: [-4.986, 13.716]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 7:\n",
      "Image value range: [-3.634, 12.997]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 8:\n",
      "Image value range: [-5.502, 11.336]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 9:\n",
      "Image value range: [-4.710, 11.241]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Class distribution:\n",
      "Class 0.0: 88051681 voxels (98.62%)\n",
      "Class 1.0: 786221 voxels (0.88%)\n",
      "Class 2.0: 197447 voxels (0.22%)\n",
      "Class 3.0: 244651 voxels (0.27%)\n",
      "\n",
      "Creating train/val split...\n",
      "Total valid patches: 388\n",
      "Total valid patches: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Viku/GitHub/Decathlon-Medical-Dataset/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started. Press the Stop button or Ctrl+C to stop training safely.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Viku/GitHub/Decathlon-Medical-Dataset/.venv/lib/python3.12/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_106']. Received: the structure of inputs=*\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.1764 - loss: 0.7880 - mean_io_u_2: 0.3849 - precision_2: 0.6098 - recall_2: 0.2243\n",
      "Epoch 1: val_dice_coefficient improved from -inf to 0.17057, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 1: saving model to checkpoint_epoch_01.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 1s/step - dice_coefficient: 0.1765 - loss: 0.7879 - mean_io_u_2: 0.3849 - precision_2: 0.6101 - recall_2: 0.2246 - val_dice_coefficient: 0.1706 - val_loss: 0.7896 - val_mean_io_u_2: 0.3750 - val_precision_2: 0.4740 - val_recall_2: 0.3277 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.2590 - loss: 0.7151 - mean_io_u_2: 0.3855 - precision_2: 0.7516 - recall_2: 0.4443\n",
      "Epoch 2: val_dice_coefficient improved from 0.17057 to 0.21956, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 2: saving model to checkpoint_epoch_02.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 1s/step - dice_coefficient: 0.2590 - loss: 0.7151 - mean_io_u_2: 0.3855 - precision_2: 0.7516 - recall_2: 0.4443 - val_dice_coefficient: 0.2196 - val_loss: 0.7561 - val_mean_io_u_2: 0.3750 - val_precision_2: 0.6019 - val_recall_2: 0.5382 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.2927 - loss: 0.6838 - mean_io_u_2: 0.3845 - precision_2: 0.7709 - recall_2: 0.5079\n",
      "Epoch 3: val_dice_coefficient improved from 0.21956 to 0.25812, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 3: saving model to checkpoint_epoch_03.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 1s/step - dice_coefficient: 0.2927 - loss: 0.6838 - mean_io_u_2: 0.3845 - precision_2: 0.7709 - recall_2: 0.5079 - val_dice_coefficient: 0.2581 - val_loss: 0.7149 - val_mean_io_u_2: 0.3750 - val_precision_2: 0.6260 - val_recall_2: 0.5573 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.3180 - loss: 0.6616 - mean_io_u_2: 0.3858 - precision_2: 0.7881 - recall_2: 0.5172\n",
      "Epoch 4: val_dice_coefficient improved from 0.25812 to 0.31002, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 4: saving model to checkpoint_epoch_04.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 1s/step - dice_coefficient: 0.3180 - loss: 0.6616 - mean_io_u_2: 0.3858 - precision_2: 0.7881 - recall_2: 0.5173 - val_dice_coefficient: 0.3100 - val_loss: 0.6670 - val_mean_io_u_2: 0.3750 - val_precision_2: 0.7614 - val_recall_2: 0.7263 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.3379 - loss: 0.6424 - mean_io_u_2: 0.3840 - precision_2: 0.7991 - recall_2: 0.5784\n",
      "Epoch 5: val_dice_coefficient did not improve from 0.31002\n",
      "\n",
      "Epoch 5: saving model to checkpoint_epoch_05.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 1s/step - dice_coefficient: 0.3379 - loss: 0.6424 - mean_io_u_2: 0.3840 - precision_2: 0.7991 - recall_2: 0.5784 - val_dice_coefficient: 0.2725 - val_loss: 0.6996 - val_mean_io_u_2: 0.3750 - val_precision_2: 0.5968 - val_recall_2: 0.5697 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.3536 - loss: 0.6278 - mean_io_u_2: 0.3839 - precision_2: 0.8015 - recall_2: 0.5866\n",
      "Epoch 6: val_dice_coefficient improved from 0.31002 to 0.32730, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 6: saving model to checkpoint_epoch_06.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 1s/step - dice_coefficient: 0.3537 - loss: 0.6278 - mean_io_u_2: 0.3839 - precision_2: 0.8016 - recall_2: 0.5866 - val_dice_coefficient: 0.3273 - val_loss: 0.6416 - val_mean_io_u_2: 0.3751 - val_precision_2: 0.7861 - val_recall_2: 0.7703 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.3872 - loss: 0.5964 - mean_io_u_2: 0.3862 - precision_2: 0.8235 - recall_2: 0.5805\n",
      "Epoch 7: val_dice_coefficient improved from 0.32730 to 0.37872, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 7: saving model to checkpoint_epoch_07.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 1s/step - dice_coefficient: 0.3872 - loss: 0.5964 - mean_io_u_2: 0.3862 - precision_2: 0.8235 - recall_2: 0.5805 - val_dice_coefficient: 0.3787 - val_loss: 0.6002 - val_mean_io_u_2: 0.3750 - val_precision_2: 0.8365 - val_recall_2: 0.8251 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.3997 - loss: 0.5832 - mean_io_u_2: 0.3857 - precision_2: 0.8317 - recall_2: 0.5889\n",
      "Epoch 8: val_dice_coefficient improved from 0.37872 to 0.38844, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 8: saving model to checkpoint_epoch_08.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 1s/step - dice_coefficient: 0.3997 - loss: 0.5832 - mean_io_u_2: 0.3857 - precision_2: 0.8317 - recall_2: 0.5889 - val_dice_coefficient: 0.3884 - val_loss: 0.5860 - val_mean_io_u_2: 0.3758 - val_precision_2: 0.8544 - val_recall_2: 0.8438 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.4103 - loss: 0.5706 - mean_io_u_2: 0.3842 - precision_2: 0.8484 - recall_2: 0.6442\n",
      "Epoch 9: val_dice_coefficient improved from 0.38844 to 0.40661, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 9: saving model to checkpoint_epoch_09.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 1s/step - dice_coefficient: 0.4103 - loss: 0.5705 - mean_io_u_2: 0.3842 - precision_2: 0.8484 - recall_2: 0.6442 - val_dice_coefficient: 0.4066 - val_loss: 0.5619 - val_mean_io_u_2: 0.3750 - val_precision_2: 0.8261 - val_recall_2: 0.8222 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.4422 - loss: 0.5420 - mean_io_u_2: 0.3852 - precision_2: 0.8688 - recall_2: 0.6183\n",
      "Epoch 10: val_dice_coefficient improved from 0.40661 to 0.42556, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 10: saving model to checkpoint_epoch_10.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 1s/step - dice_coefficient: 0.4422 - loss: 0.5420 - mean_io_u_2: 0.3852 - precision_2: 0.8688 - recall_2: 0.6183 - val_dice_coefficient: 0.4256 - val_loss: 0.5428 - val_mean_io_u_2: 0.3757 - val_precision_2: 0.8979 - val_recall_2: 0.8943 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.4428 - loss: 0.5396 - mean_io_u_2: 0.3841 - precision_2: 0.8747 - recall_2: 0.6572\n",
      "Epoch 11: val_dice_coefficient improved from 0.42556 to 0.43174, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 11: saving model to checkpoint_epoch_11.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 1s/step - dice_coefficient: 0.4428 - loss: 0.5396 - mean_io_u_2: 0.3841 - precision_2: 0.8748 - recall_2: 0.6572 - val_dice_coefficient: 0.4317 - val_loss: 0.5453 - val_mean_io_u_2: 0.3753 - val_precision_2: 0.8348 - val_recall_2: 0.8321 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.4772 - loss: 0.5077 - mean_io_u_2: 0.3849 - precision_2: 0.8948 - recall_2: 0.6613\n",
      "Epoch 12: val_dice_coefficient improved from 0.43174 to 0.44406, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 12: saving model to checkpoint_epoch_12.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 1s/step - dice_coefficient: 0.4772 - loss: 0.5077 - mean_io_u_2: 0.3848 - precision_2: 0.8948 - recall_2: 0.6613 - val_dice_coefficient: 0.4441 - val_loss: 0.5261 - val_mean_io_u_2: 0.3754 - val_precision_2: 0.9025 - val_recall_2: 0.8998 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.4833 - loss: 0.4984 - mean_io_u_2: 0.3844 - precision_2: 0.8914 - recall_2: 0.6641\n",
      "Epoch 13: val_dice_coefficient improved from 0.44406 to 0.47997, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 13: saving model to checkpoint_epoch_13.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 1s/step - dice_coefficient: 0.4832 - loss: 0.4984 - mean_io_u_2: 0.3844 - precision_2: 0.8914 - recall_2: 0.6641 - val_dice_coefficient: 0.4800 - val_loss: 0.4812 - val_mean_io_u_2: 0.3750 - val_precision_2: 0.9268 - val_recall_2: 0.9251 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.4764 - loss: 0.5033 - mean_io_u_2: 0.3833 - precision_2: 0.9018 - recall_2: 0.6851\n",
      "Epoch 14: val_dice_coefficient improved from 0.47997 to 0.48923, saving model to best_3d_model_weighted.keras\n",
      "\n",
      "Epoch 14: saving model to checkpoint_epoch_14.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 1s/step - dice_coefficient: 0.4765 - loss: 0.5033 - mean_io_u_2: 0.3833 - precision_2: 0.9018 - recall_2: 0.6851 - val_dice_coefficient: 0.4892 - val_loss: 0.4736 - val_mean_io_u_2: 0.3750 - val_precision_2: 0.9614 - val_recall_2: 0.9600 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coefficient: 0.4953 - loss: 0.4866 - mean_io_u_2: 0.3839 - precision_2: 0.9040 - recall_2: 0.7048\n",
      "Epoch 15: val_dice_coefficient did not improve from 0.48923\n",
      "\n",
      "Epoch 15: saving model to checkpoint_epoch_15.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 1s/step - dice_coefficient: 0.4953 - loss: 0.4865 - mean_io_u_2: 0.3839 - precision_2: 0.9041 - recall_2: 0.7048 - val_dice_coefficient: 0.4892 - val_loss: 0.4737 - val_mean_io_u_2: 0.3750 - val_precision_2: 0.9550 - val_recall_2: 0.9532 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m105/388\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:36\u001b[0m 1s/step - dice_coefficient: 0.5208 - loss: 0.4610 - mean_io_u_2: 0.3863 - precision_2: 0.9204 - recall_2: 0.6388"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Set memory growth for GPU\n",
    "        physical_devices = tf.config.list_physical_devices('GPU')\n",
    "        if physical_devices:\n",
    "            print(f\"Found {len(physical_devices)} GPU(s)\")\n",
    "            for device in physical_devices:\n",
    "                tf.config.experimental.set_memory_growth(device, True)\n",
    "                print(f\"Enabled memory growth for {device}\")\n",
    "        else:\n",
    "            print(\"No GPU devices found. Running on CPU.\")\n",
    "\n",
    "        # Initialize dataset\n",
    "        print(\"\\nInitializing dataset...\")\n",
    "        dataset = BrainTumor3DDataset(base_path='.')\n",
    "        \n",
    "        # Load and prepare data\n",
    "        num_samples = 10  # Adjust based on your available memory\n",
    "        print(f\"\\nLoading {num_samples} samples...\")\n",
    "        images, labels = dataset.prepare_data(num_samples=num_samples)\n",
    "        \n",
    "        # Analyze class distribution before training\n",
    "        class_counts, class_percentages = dataset.analyze_class_distribution(labels)\n",
    "        print(\"\\nClass distribution before training:\")\n",
    "        for class_idx, count in class_counts.items():\n",
    "            print(f\"Class {class_idx}: {count:,} voxels ({class_percentages[class_idx]:.2f}%)\")\n",
    "        \n",
    "        # Split data\n",
    "        validation_split = 0.2\n",
    "        print(f\"\\nSplitting data with {validation_split:.0%} validation split...\")\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            images, labels, \n",
    "            test_size=validation_split, \n",
    "            random_state=42,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        # Clear original arrays to free memory\n",
    "        del images, labels\n",
    "        gc.collect()\n",
    "        \n",
    "        # Create data generators\n",
    "        patch_size = (64, 64, 64)\n",
    "        print(\"\\nInitializing data generators...\")\n",
    "        train_generator = DataGenerator3D(\n",
    "            X_train, y_train,\n",
    "            batch_size=1,\n",
    "            patch_size=patch_size,\n",
    "            augment=True\n",
    "        )\n",
    "        \n",
    "        val_generator = DataGenerator3D(\n",
    "            X_val, y_val,\n",
    "            batch_size=1,\n",
    "            patch_size=patch_size,\n",
    "            augment=False\n",
    "        )\n",
    "        \n",
    "        print(f\"Training samples: {len(train_generator)}\")\n",
    "        print(f\"Validation samples: {len(val_generator)}\")\n",
    "        \n",
    "        # Train model with weighted loss\n",
    "        print(\"\\nStarting model training...\")\n",
    "        max_epochs = 30  # Adjust based on your needs\n",
    "        model, history = train_weighted_model(\n",
    "            validation_split=validation_split,\n",
    "            max_epochs=max_epochs,\n",
    "            num_samples=num_samples\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        print(\"\\nEvaluating model...\")\n",
    "        accuracy, mean_dice, conf_matrix = evaluate_weighted_model(model, val_generator)\n",
    "        \n",
    "        # Plot and save training history\n",
    "        print(\"\\nPlotting training history...\")\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Loss plot\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Weighted Dice Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Dice coefficient plot\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(history.history['dice_coefficient'], label='Training Dice')\n",
    "        plt.plot(history.history['val_dice_coefficient'], label='Validation Dice')\n",
    "        plt.title('Dice Coefficient')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Dice Score')\n",
    "        plt.legend()\n",
    "        \n",
    "        # IoU plot\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(history.history['mean_io_u'], label='Training IoU')\n",
    "        plt.plot(history.history['val_mean_io_u'], label='Validation IoU')\n",
    "        plt.title('Mean IoU')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('IoU Score')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history_3d.png')\n",
    "        plt.show()\n",
    "        \n",
    "        # Save final model\n",
    "        print(\"\\nSaving final model...\")\n",
    "        model.save('final_brain_tumor_model.keras')\n",
    "        \n",
    "        # Save training history\n",
    "        print(\"Saving training history...\")\n",
    "        with open('training_history.json', 'w') as f:\n",
    "            json.dump(history.history, f)\n",
    "            \n",
    "        print(\"\\nTraining completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Try to save model if it exists\n",
    "        if 'model' in locals():\n",
    "            try:\n",
    "                model.save('emergency_saved_model.keras')\n",
    "                print('Emergency model save successful')\n",
    "            except:\n",
    "                print('Failed to save model during error recovery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
