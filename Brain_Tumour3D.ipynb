{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from scipy.ndimage import rotate\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumor3DDataset:\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = base_path\n",
    "        self.dataset_json = self._load_dataset_json()\n",
    "        self.train_files = self._get_training_files()\n",
    "        \n",
    "    def _load_dataset_json(self):\n",
    "        json_path = os.path.join(self.base_path, 'ML_Decathlon_Dataset/Task01_BrainTumour/dataset.json')\n",
    "        with open(json_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def _get_training_files(self):\n",
    "        return self.dataset_json['training']\n",
    "    \n",
    "    def validate_data_integrity(self, images, labels):\n",
    "        \"\"\"Validate data integrity and check for potential issues.\"\"\"\n",
    "        print(\"\\nData Validation Report:\")\n",
    "        print(\"-----------------------\")\n",
    "        \n",
    "        # Check shapes\n",
    "        print(f\"Number of samples: {len(images)}\")\n",
    "        print(f\"Image shape: {images[0].shape}\")\n",
    "        print(f\"Label shape: {labels[0].shape}\")\n",
    "        \n",
    "        # Check value ranges\n",
    "        for i, (img, lbl) in enumerate(zip(images, labels)):\n",
    "            print(f\"\\nSample {i}:\")\n",
    "            print(f\"Image value range: [{np.min(img):.3f}, {np.max(img):.3f}]\")\n",
    "            print(f\"Unique labels: {np.unique(lbl)}\")\n",
    "            \n",
    "            # Check for NaN/Inf\n",
    "            if np.any(np.isnan(img)) or np.any(np.isinf(img)):\n",
    "                print(\"WARNING: Found NaN or Inf values in image!\")\n",
    "            \n",
    "            # Check label validity\n",
    "            if not np.array_equal(np.unique(lbl), np.arange(len(np.unique(lbl)))):\n",
    "                print(\"WARNING: Labels might not be consecutive integers!\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def load_volume(self, file_path):\n",
    "        full_path = os.path.join(self.base_path, 'ML_Decathlon_Dataset/Task01_BrainTumour', \n",
    "                                file_path.replace('./', ''))\n",
    "        return nib.load(full_path).get_fdata()\n",
    "\n",
    "    def analyze_class_distribution(self, labels):\n",
    "        \"\"\"Analyze class distribution in the dataset\"\"\"\n",
    "        class_counts = {}\n",
    "        total_voxels = 0\n",
    "        \n",
    "        for label_volume in labels:\n",
    "            unique, counts = np.unique(label_volume, return_counts=True)\n",
    "            total_voxels += label_volume.size\n",
    "            \n",
    "            for class_idx, count in zip(unique, counts):\n",
    "                if class_idx not in class_counts:\n",
    "                    class_counts[class_idx] = 0\n",
    "                class_counts[class_idx] += count\n",
    "        \n",
    "        # Convert to percentages\n",
    "        class_percentages = {k: (v/total_voxels)*100 for k, v in class_counts.items()}\n",
    "        \n",
    "        return class_counts, class_percentages\n",
    "\n",
    "    def preprocess_volume(self, volume):\n",
    "        \"\"\"Optimized preprocessing using vectorized operations\"\"\"\n",
    "        preprocessed = np.zeros_like(volume, dtype=np.float32)\n",
    "        for i in range(volume.shape[-1]):\n",
    "            modality = volume[..., i]\n",
    "            nonzero_mask = modality != 0\n",
    "            if np.any(nonzero_mask):\n",
    "                mean = np.mean(modality[nonzero_mask])\n",
    "                std = np.std(modality[nonzero_mask])\n",
    "                if std != 0:\n",
    "                    preprocessed[..., i] = (modality - mean) / std\n",
    "        return preprocessed\n",
    "\n",
    "    def prepare_data(self, num_samples=None):\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        train_files = self.train_files[:num_samples] if num_samples else self.train_files\n",
    "        \n",
    "        for idx, file_info in tqdm(enumerate(train_files), desc=\"Loading data\", total=len(train_files)):\n",
    "            try:\n",
    "                image = self.load_volume(file_info['image'])\n",
    "                label = self.load_volume(file_info['label'])\n",
    "                \n",
    "                # Check for potential data issues\n",
    "                if np.any(np.isnan(image)) or np.any(np.isinf(image)):\n",
    "                    print(f\"Warning: Found NaN or Inf values in image {idx}\")\n",
    "                    continue\n",
    "                \n",
    "                image = self.preprocess_volume(image)\n",
    "                \n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "                gc.collect()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {idx}: {e}\")\n",
    "                continue\n",
    "            \n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator3D(Sequence):\n",
    "    def __init__(self, image_list, label_list, batch_size=1, patch_size=(64, 64, 64),\n",
    "                 n_channels=4, n_classes=4, shuffle=True, augment=False):\n",
    "        self.image_list = image_list\n",
    "        self.label_list = label_list\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        \n",
    "        self.valid_patches = []\n",
    "        self._calculate_valid_patches()\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def _calculate_valid_patches(self):\n",
    "        valid_patches = []\n",
    "        stride = [p // 2 for p in self.patch_size]\n",
    "        \n",
    "        for idx, image in enumerate(self.image_list):\n",
    "            x_coords = range(0, image.shape[0] - self.patch_size[0], stride[0])\n",
    "            y_coords = range(0, image.shape[1] - self.patch_size[1], stride[1])\n",
    "            z_coords = range(0, image.shape[2] - self.patch_size[2], stride[2])\n",
    "            \n",
    "            for x in x_coords:\n",
    "                for y in y_coords:\n",
    "                    for z in z_coords:\n",
    "                        label_patch = self.label_list[idx][\n",
    "                            x:x + self.patch_size[0],\n",
    "                            y:y + self.patch_size[1],\n",
    "                            z:z + self.patch_size[2]\n",
    "                        ]\n",
    "                        if np.any(label_patch):  # Only include patches with labels\n",
    "                            valid_patches.append((idx, x, y, z))\n",
    "        \n",
    "        self.valid_patches = valid_patches\n",
    "        print(f\"Total valid patches: {len(self.valid_patches)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.valid_patches) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = min((index + 1) * self.batch_size, len(self.valid_patches))\n",
    "        batch_patches = self.valid_patches[start_idx:end_idx]\n",
    "        \n",
    "        batch_size = len(batch_patches)\n",
    "        X = np.zeros((batch_size, *self.patch_size, self.n_channels), dtype=np.float32)\n",
    "        y = np.zeros((batch_size, *self.patch_size, self.n_classes), dtype=np.float32)\n",
    "\n",
    "        for i, (img_idx, x, y_coord, z) in enumerate(batch_patches):\n",
    "            X[i], y[i] = self._extract_patch(img_idx, x, y_coord, z)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def _extract_patch(self, img_idx, x, y, z):\n",
    "        image = self.image_list[img_idx]\n",
    "        label = self.label_list[img_idx]\n",
    "\n",
    "        patch_x = image[x:x + self.patch_size[0],\n",
    "                       y:y + self.patch_size[1],\n",
    "                       z:z + self.patch_size[2]].astype(np.float32)\n",
    "\n",
    "        patch_y = np.zeros((*self.patch_size, self.n_classes), dtype=np.float32)\n",
    "        for c in range(self.n_classes):\n",
    "            patch_y[..., c] = (label[x:x + self.patch_size[0],\n",
    "                                    y:y + self.patch_size[1],\n",
    "                                    z:z + self.patch_size[2]] == c)\n",
    "\n",
    "        if self.augment:\n",
    "            patch_x, patch_y = self._augment_data(patch_x, patch_y)\n",
    "\n",
    "        return patch_x, patch_y\n",
    "\n",
    "    @staticmethod\n",
    "    def _augment_data(image, label):\n",
    "        if np.random.random() > 0.5:\n",
    "            angle = np.random.uniform(-20, 20)\n",
    "            image = np.stack([rotate(image[..., c], angle, axes=(0, 1), reshape=False)\n",
    "                            for c in range(image.shape[-1])], axis=-1)\n",
    "            label = np.stack([rotate(label[..., c], angle, axes=(0, 1), reshape=False)\n",
    "                            for c in range(label.shape[-1])], axis=-1)\n",
    "        return image, label\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.valid_patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3d_unet(input_shape, n_classes=4, n_filters=16):\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = conv_block_3d(inputs, n_filters)\n",
    "    pool1 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "    \n",
    "    conv2 = conv_block_3d(pool1, n_filters*2)\n",
    "    pool2 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "    \n",
    "    conv3 = conv_block_3d(pool2, n_filters*4)\n",
    "    pool3 = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "    \n",
    "    # Bridge\n",
    "    conv4 = conv_block_3d(pool3, n_filters*8)\n",
    "    \n",
    "    # Decoder\n",
    "    up5 = tf.keras.layers.Conv3DTranspose(n_filters*4, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv4)\n",
    "    concat5 = tf.keras.layers.concatenate([up5, conv3])\n",
    "    conv5 = conv_block_3d(concat5, n_filters*4)\n",
    "    \n",
    "    up6 = tf.keras.layers.Conv3DTranspose(n_filters*2, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv5)\n",
    "    concat6 = tf.keras.layers.concatenate([up6, conv2])\n",
    "    conv6 = conv_block_3d(concat6, n_filters*2)\n",
    "    \n",
    "    up7 = tf.keras.layers.Conv3DTranspose(n_filters, (2, 2, 2), strides=(2, 2, 2), padding='same')(conv6)\n",
    "    concat7 = tf.keras.layers.concatenate([up7, conv1])\n",
    "    conv7 = conv_block_3d(concat7, n_filters)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv3D(n_classes, (1, 1, 1), activation='softmax')(conv7)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_3d(inputs, n_filters, kernel_size=(3, 3, 3)):\n",
    "    x = tf.keras.layers.Conv3D(n_filters, kernel_size, padding='same')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv3D(n_filters, kernel_size, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-5\n",
    "    \n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred) + smooth\n",
    "    denominator = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth\n",
    "    \n",
    "    return 1 - numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingController:\n",
    "    def __init__(self):\n",
    "        self.stop_training = False\n",
    "        self.button = widgets.Button(description='Stop Training')\n",
    "        self.button.on_click(self.on_button_clicked)\n",
    "        display(self.button)\n",
    "    \n",
    "    def on_button_clicked(self, b):\n",
    "        self.stop_training = True\n",
    "        print(\"\\nStopping training after current epoch completes...\")\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, controller):\n",
    "        super().__init__()\n",
    "        self.controller = controller\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.controller.stop_training:\n",
    "            self.model.stop_training = True\n",
    "            print(\"\\nSaving model...\")\n",
    "            self.model.save(f'model_stopped_epoch_{epoch}.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(validation_split=0.2, max_epochs=30, num_samples=10):\n",
    "    try:\n",
    "        # Initialize controller\n",
    "        controller = TrainingController()\n",
    "        \n",
    "        # Load and prepare data\n",
    "        dataset = BrainTumor3DDataset(base_path='.')\n",
    "        print(\"Starting data preparation...\")\n",
    "        images, labels = dataset.prepare_data(num_samples=num_samples)\n",
    "        \n",
    "        # Validate data\n",
    "        dataset.validate_data_integrity(images, labels)\n",
    "        \n",
    "        # Split data\n",
    "        print(\"\\nCreating train/val split...\")\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            images, labels, test_size=validation_split, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Clear memory\n",
    "        del images, labels\n",
    "        gc.collect()\n",
    "        \n",
    "        # Create data generators\n",
    "        patch_size = (64, 64, 64)\n",
    "        train_generator = DataGenerator3D(\n",
    "            X_train, y_train, batch_size=1, patch_size=patch_size, augment=True\n",
    "        )\n",
    "        val_generator = DataGenerator3D(\n",
    "            X_val, y_val, batch_size=1, patch_size=patch_size, augment=False\n",
    "        )\n",
    "        \n",
    "        # Create and compile model\n",
    "        input_shape = (*patch_size, 4)\n",
    "        model = create_3d_unet(input_shape, n_classes=4)\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=dice_loss,\n",
    "            metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=4)]\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            CustomCallback(controller),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=5,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                'best_3d_model.keras',\n",
    "                save_best_only=True,\n",
    "                monitor='val_loss',\n",
    "                verbose=1\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=3,\n",
    "                min_lr=1e-6,\n",
    "                verbose=1\n",
    "            ),\n",
    "            tf.keras.callbacks.CSVLogger('training_log.csv')\n",
    "        ]\n",
    "        \n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data=val_generator,\n",
    "            epochs=max_epochs,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        return model, history\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'\\nAn error occurred during training: {str(e)}')\n",
    "        if 'model' in locals():\n",
    "            model.save('error_model.keras')\n",
    "            print('Model saved as error_model.keras')\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_generator):\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(\"----------------\")\n",
    "    \n",
    "    val_predictions = []\n",
    "    val_true = []\n",
    "    \n",
    "    for i in tqdm(range(len(val_generator)), desc=\"Evaluating\"):\n",
    "        x, y = val_generator[i]\n",
    "        pred = model.predict(x, verbose=0)\n",
    "        val_predictions.append(pred)\n",
    "        val_true.append(y)\n",
    "    \n",
    "    val_pred = np.concatenate(val_predictions)\n",
    "    val_true = np.concatenate(val_true)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = np.mean(np.argmax(val_pred, axis=-1) == np.argmax(val_true, axis=-1))\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(\n",
    "        np.argmax(val_true.reshape(-1, val_true.shape[-1]), axis=-1),\n",
    "        np.argmax(val_pred.reshape(-1, val_pred.shape[-1]), axis=-1)\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Per-class metrics\n",
    "    for i in range(val_true.shape[-1]):\n",
    "        class_acc = np.mean(\n",
    "            np.argmax(val_pred, axis=-1)[np.argmax(val_true, axis=-1) == i] == i\n",
    "        )\n",
    "        print(f\"Class {i} Accuracy: {class_acc:.4f}\")\n",
    "    \n",
    "    return accuracy, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9041e1697bef49a7b8c4ec89f965910f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Stop Training', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preparation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 10/10 [00:04<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Validation Report:\n",
      "-----------------------\n",
      "Number of samples: 10\n",
      "Image shape: (240, 240, 155, 4)\n",
      "Label shape: (240, 240, 155)\n",
      "\n",
      "Sample 0:\n",
      "Image value range: [-5.103, 10.282]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 1:\n",
      "Image value range: [-3.452, 12.930]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 2:\n",
      "Image value range: [-4.458, 11.208]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 3:\n",
      "Image value range: [-4.506, 12.677]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 4:\n",
      "Image value range: [-3.708, 12.848]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 5:\n",
      "Image value range: [-5.864, 10.379]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 6:\n",
      "Image value range: [-4.986, 13.716]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 7:\n",
      "Image value range: [-3.634, 12.997]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 8:\n",
      "Image value range: [-5.502, 11.336]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Sample 9:\n",
      "Image value range: [-4.710, 11.241]\n",
      "Unique labels: [0. 1. 2. 3.]\n",
      "\n",
      "Creating train/val split...\n",
      "Total valid patches: 388\n",
      "Total valid patches: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Viku/GitHub/Decathlon-Medical-Dataset/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Viku/GitHub/Decathlon-Medical-Dataset/.venv/lib/python3.12/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor']. Received: the structure of inputs=*\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5908 - loss: 0.6404 - mean_io_u: 0.3846\n",
      "Epoch 1: val_loss improved from inf to 0.49654, saving model to best_3d_model.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 1s/step - accuracy: 0.5909 - loss: 0.6402 - mean_io_u: 0.3846 - val_accuracy: 0.7939 - val_loss: 0.4965 - val_mean_io_u: 0.3750 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7449 - loss: 0.4640 - mean_io_u: 0.3858\n",
      "Epoch 2: val_loss improved from 0.49654 to 0.42923, saving model to best_3d_model.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 1s/step - accuracy: 0.7452 - loss: 0.4639 - mean_io_u: 0.3858 - val_accuracy: 0.8997 - val_loss: 0.4292 - val_mean_io_u: 0.3778 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9151 - loss: 0.3684 - mean_io_u: 0.3846\n",
      "Epoch 3: val_loss improved from 0.42923 to 0.33803, saving model to best_3d_model.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 1s/step - accuracy: 0.9152 - loss: 0.3683 - mean_io_u: 0.3846 - val_accuracy: 0.8992 - val_loss: 0.3380 - val_mean_io_u: 0.3752 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9346 - loss: 0.2793 - mean_io_u: 0.3852\n",
      "Epoch 4: val_loss improved from 0.33803 to 0.25358, saving model to best_3d_model.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 1s/step - accuracy: 0.9347 - loss: 0.2792 - mean_io_u: 0.3852 - val_accuracy: 0.9450 - val_loss: 0.2536 - val_mean_io_u: 0.3763 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9433 - loss: 0.2103 - mean_io_u: 0.3856\n",
      "Epoch 5: val_loss improved from 0.25358 to 0.18097, saving model to best_3d_model.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 1s/step - accuracy: 0.9433 - loss: 0.2102 - mean_io_u: 0.3856 - val_accuracy: 0.9586 - val_loss: 0.1810 - val_mean_io_u: 0.3758 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9530 - loss: 0.1604 - mean_io_u: 0.3853\n",
      "Epoch 6: val_loss improved from 0.18097 to 0.09485, saving model to best_3d_model.keras\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 1s/step - accuracy: 0.9530 - loss: 0.1604 - mean_io_u: 0.3853 - val_accuracy: 0.9670 - val_loss: 0.0949 - val_mean_io_u: 0.3778 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9557 - loss: 0.1286 - mean_io_u: 0.3844\n",
      "Epoch 7: val_loss did not improve from 0.09485\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 1s/step - accuracy: 0.9557 - loss: 0.1286 - mean_io_u: 0.3844 - val_accuracy: 0.9667 - val_loss: 0.1044 - val_mean_io_u: 0.3757 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m177/388\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:46\u001b[0m 1s/step - accuracy: 0.9656 - loss: 0.1022 - mean_io_u: 0.3852"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set memory growth for GPU\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if physical_devices:\n",
    "        for device in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "    \n",
    "    # Train model\n",
    "    model, history = train_model(num_samples=10)\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history.history['mean_io_u'], label='Training IoU')\n",
    "    plt.plot(history.history['val_mean_io_u'], label='Validation IoU')\n",
    "    plt.title('Mean IoU')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history_3d.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
